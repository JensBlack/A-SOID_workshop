{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(r'/Users/alexanderhsu/Google Drive/My Drive/2023Data/asoid_manuscript/active_learning_fixed_2newgroups.sav', 'rb') as fr:\n",
    "    [X_train_list, Y_train_list,\n",
    "     iterX_f1_scores_list, iterX_macro_scores_list, iterX_predict_prob_list,\n",
    "     sampled_idx_list] = joblib.load(fr)\n",
    "with open(r'/Users/alexanderhsu/Google Drive/My Drive/2023Data/asoid_manuscript/using_all_train_2newgroups.sav', 'rb') as fr:\n",
    "    [subsampled_features_list, subsampled_targets_list,\n",
    "     remaining_features_list, remaining_targets_list,\n",
    "     peak_f1_scores, peak_macro_scores, peak_predict_prob] = joblib.load(fr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1_ = []\n",
    "macro_avg_ = []\n",
    "for j in range(len(iterX_f1_scores_list)):\n",
    "    f1_.append(np.array(iterX_f1_scores_list[j]))\n",
    "    macro_avg_.append(np.array(iterX_macro_scores_list[j]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "behavior_types = ['Average', 'Attack', 'Investigation', 'Mount', 'Anogential1', 'Anogential2']\n",
    "cmap_beh = ['crimson', 'darkorange', 'steelblue', 'plum', 'goldenrod']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# plot error bar with line for asoid indiv f1\n",
    "for b in range(len(cmap_beh)):\n",
    "    x = np.arange(len(f1_))\n",
    "    y = np.median(f1_, axis=1)[:, b]\n",
    "    y_err = np.std(macro_avg_, axis=1)\n",
    "    ax.errorbar(x, y, yerr=y_err, barsabove=True, lw=3,\n",
    "                color=cmap_beh[b], ecolor=cmap_beh[b], alpha=0.8, elinewidth=3)\n",
    "# in terms of macro f1\n",
    "x_all = np.arange(len(macro_avg_))\n",
    "y_all = np.mean(macro_avg_, axis=1)\n",
    "std_all = np.std(macro_avg_, axis=1)\n",
    "plot, caps, bar = ax.errorbar(x_all, y_all, yerr=std_all, barsabove=True, lw=3,\n",
    "                              color='k', ecolor='k', alpha=0.8, elinewidth=3)\n",
    "\n",
    "ax.set_xticks(np.arange(4, len(macro_avg_), 5))\n",
    "ax.set_xticklabels(np.arange(5, len(macro_avg_)+1, 5))\n",
    "ax.set_ylabel('F1 score')\n",
    "ax.set_xlabel('Active learning iteration #')\n",
    "ax.set_ylim([0.65, 0.95])\n",
    "# plot performance line using all data\n",
    "ax.hlines(np.median(peak_macro_scores, axis=0),\n",
    "          0,\n",
    "          len(macro_avg_)-1,\n",
    "          ls='--',\n",
    "          color='k')\n",
    "for b in range(len(cmap_beh)):\n",
    "    ax.hlines(np.median(peak_f1_scores, axis=0)[b],\n",
    "              0,\n",
    "              len(macro_avg_)-1,\n",
    "              ls='--',\n",
    "              color=cmap_beh[b])\n",
    "ax.set_xlim([-.5, len(macro_avg_)-.5])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.legend(behavior_types)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "behavior_types = ['Average', 'Attack', 'Investigation', 'Mount', 'Anogential1', 'Anogential2']\n",
    "## plot average counts across 20 seeds, and compare with all avail training\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 1))\n",
    "class_counts_per = [np.hstack([np.mean([len(np.where(Y_train_list[it][i]==b)[0])\n",
    "                                        for i in range(len(Y_train_list[it]))])\n",
    "                               for it in range(len(Y_train_list))])\n",
    "                    for b in np.unique(Y_train_list[0][0])]\n",
    "\n",
    "class_counts_total = [len(np.where(subsampled_targets_list[0][subsampled_targets_list[0] < 5] == b)[0])\n",
    "                      for b in np.unique(subsampled_targets_list[0]) if b < 5]\n",
    "\n",
    "df_all = pd.DataFrame(np.vstack((np.array(class_counts_per).T, np.array(class_counts_total))))\n",
    "df_all.plot(kind='bar', stacked=True, legend=False, color=cmap_beh, ax=ax)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_yticklabels('')\n",
    "ax.set_xticks(np.hstack((np.arange(4, 20, 5), 20)))\n",
    "ax.set_yticks(np.arange(2000, 15000, 6000))\n",
    "ax.legend(behavior_types)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "behavior_types = ['Average', 'Attack', 'Investigation', 'Mount', 'Anogential1', 'Anogential2']\n",
    "## plot average counts across 20 seeds\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 1))\n",
    "df_activeonly = pd.DataFrame(np.vstack((np.array(class_counts_per).T)))\n",
    "# stack bar\n",
    "df_activeonly.plot(kind='bar', stacked=True, legend=False, color=cmap_beh, ax=ax)\n",
    "ax.set_xticklabels('')\n",
    "ax.set_yticklabels('')\n",
    "ax.set_xticks(np.hstack((np.arange(4, 20, 5), 20)))\n",
    "ax.set_yticks(np.arange(0, 3000, 1000))\n",
    "ax.legend(behavior_types)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
